{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --user install fuzzywuzzy PyShp geopandas rtree matplotlib cartopy cython cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "running-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import shapefile\n",
    "import zipfile\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from cartopy import crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspended-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read intermediate canonical facilities into dataframe\n",
    "intermediate_url=\"https://raw.githubusercontent.com/PTDP/data/main/intermediate_data/intermediate_company_facilities.csv\"\n",
    "intermediate = pd.read_csv(intermediate_url)\n",
    "\n",
    "hifld_url=\"https://opendata.arcgis.com/datasets/2d6109d4127d458eaf0958e4c5296b67_0.csv?outSR=%7B%22latestWkid%22%3A3857%2C%22wkid%22%3A102100%7D\"\n",
    "hifld=pd.read_csv(hifld_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saved-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize facility google name\n",
    "\n",
    "# uppercase\n",
    "# remove entities before dash IL DOC - BIG MUDDY RIVER CORRECTIONAL CENTER\n",
    "\n",
    "intermediate['googlePlaceName'] = intermediate['googlePlaceName'].str.upper();\n",
    "\n",
    "#print(intermediate)\n",
    "#print(hifld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geological-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CULLMAN COUNTY DETENTION CENTER\n"
     ]
    }
   ],
   "source": [
    "#ratios = process.extract(intermediate['googlePlaceName'][0],hifld['NAME'])\n",
    "# def fuzzy_matches(googlePlaceName):\n",
    "    \n",
    "\n",
    "# highest = process.extractOne(intermediate['googlePlaceName'][0],hifld['NAME'])\n",
    "# print(highest)\n",
    "\n",
    "# goal - \n",
    "\n",
    "# geosptial join\n",
    "\n",
    "print(hifld['NAME'][1936])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "residential-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading shapefile...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Output GeoJSON Data\n",
    "hifld_shp_url=\"https://opendata.arcgis.com/datasets/2d6109d4127d458eaf0958e4c5296b67_0.zip?outSR=%7B%22latestWkid%22%3A3857%2C%22wkid%22%3A102100%7D\"\n",
    "local_path = 'hifld.zip'\n",
    "\n",
    "print('Downloading shapefile...')\n",
    "r = requests.get(hifld_shp_url)\n",
    "\n",
    "with open(local_path,'wb') as out: ## Open temporary file as bytes\n",
    "    out.write(io.BytesIO(r.content).read())                ## Read bytes into file\n",
    "\n",
    "# z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "# z.write(local_path)\n",
    "# z.close()\n",
    "print(\"Done\")\n",
    "#z.extractall(path=local_path) # extract to folder\n",
    "#filenames = [y for y in sorted(z.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx'] if y.endswith(ending)] \n",
    "#print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "systematic-showcase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  10880\n",
       "facilityInternal    10880\n",
       "agencyInternal       6612\n",
       "stateInternal       10880\n",
       "company             10880\n",
       "createdAt           10880\n",
       "googlePlaceName     10880\n",
       "address             10880\n",
       "longitude           10880\n",
       "latitude            10880\n",
       "county              10790\n",
       "googlePlaceId       10880\n",
       "state               10880\n",
       "geometry            10880\n",
       "index_right         10880\n",
       "FID                 10880\n",
       "FACILITYID          10880\n",
       "NAME                10880\n",
       "ADDRESS             10880\n",
       "CITY                10880\n",
       "STATE               10880\n",
       "ZIP                 10880\n",
       "ZIP4                10880\n",
       "TELEPHONE           10880\n",
       "TYPE                10880\n",
       "STATUS              10880\n",
       "POPULATION          10880\n",
       "COUNTY              10880\n",
       "COUNTYFIPS          10880\n",
       "COUNTRY             10880\n",
       "NAICS_CODE          10880\n",
       "NAICS_DESC          10880\n",
       "SOURCE              10880\n",
       "SOURCEDATE          10880\n",
       "VAL_METHOD          10880\n",
       "VAL_DATE            10880\n",
       "WEBSITE             10880\n",
       "SECURELVL           10880\n",
       "CAPACITY            10880\n",
       "SHAPE_Leng          10880\n",
       "SHAPE_Le_1          10880\n",
       "SHAPE_Area          10880\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(r.content)\n",
    "# hifld_geojson = shapefile.Reader(local_path + 'Prison_Boundaries.dbf').__geo_interface__\n",
    "gdf_intermediate = gpd.GeoDataFrame(intermediate, geometry=gpd.points_from_xy(intermediate.longitude, intermediate.latitude))\n",
    "\n",
    "# remove null\n",
    "gdf_intermediate = gdf_intermediate[gdf_intermediate.is_valid]\n",
    "gdf_intermediate.crs = \"EPSG:4326\"\n",
    "gdf_intermediate = gdf_intermediate.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# buffer in miles around each geocoded point\n",
    "buffer_length_in_meters = (5 * 1000) * 1.60934\n",
    "gdf_intermediate['geometry'] = gdf_intermediate.geometry.buffer(buffer_length_in_meters)\n",
    "\n",
    "# ax = gdf_intermediate.plot()\n",
    "\n",
    "# distance + name similarity score\n",
    "\n",
    "# fuzz.token_set_ratio(Str1,Str2)\n",
    "\n",
    "\n",
    "gdf_hifld = gpd.read_file(local_path)\n",
    "\n",
    "sjoined_facilities = gpd.sjoin(gdf_intermediate, gdf_hifld)\n",
    "sjoined_facilities.head()\n",
    "sjoined_facilities.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-temperature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-forest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-spell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-american",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
